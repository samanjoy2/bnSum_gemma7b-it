{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Training] Gemma 7b Bangla News Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Mar 10 11:41:38 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000               On  | 00000000:08:00.0 Off |                  Off |\n",
      "| 55%   81C    P2             299W / 300W |  32774MiB / 49140MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qqq kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "Suggested packages:\n",
      "  zip\n",
      "The following NEW packages will be installed:\n",
      "  unzip\n",
      "0 upgraded, 1 newly installed, 0 to remove and 9 not upgraded.\n",
      "Need to get 175 kB of archives.\n",
      "After this operation, 386 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 unzip amd64 6.0-26ubuntu3.2 [175 kB]\n",
      "Fetched 175 kB in 0s (626 kB/s)\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package unzip.\n",
      "(Reading database ... 16755 files and directories currently installed.)\n",
      "Preparing to unpack .../unzip_6.0-26ubuntu3.2_amd64.deb ...\n",
      "Unpacking unzip (6.0-26ubuntu3.2) ...\n",
      "Setting up unzip (6.0-26ubuntu3.2) ...\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ~/.kaggle\n",
    "!cp /home/kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bengali-news-summarization-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
      "Archive:  /home/bengali-news-summarization-dataset.zip\n",
      "  inflating: Bengali-News-Summarization-Dataset/article.txt  \n",
      "  inflating: Bengali-News-Summarization-Dataset/summary.txt  \n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d prithwirajsust/bengali-news-summarization-dataset\n",
    "!unzip /home/bengali-news-summarization-dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 19097 summary-article pairs\n",
      "There are 19097 summary-article pairs\n",
      "Finished splitting and saving dataset!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def split_dataset(path):\n",
    "    dataset = open(path, encoding='utf-8').read().split('\\n')\n",
    "\n",
    "    dataset_len = len(dataset)\n",
    "    print(\"There are %s summary-article pairs\" % dataset_len)\n",
    "\n",
    "    # Random shuffle data\n",
    "    random.seed(11)\n",
    "    dataset = np.array(random.sample(dataset, len(dataset)))\n",
    "\n",
    "    # Split dataset to 70% training, 20% validation, and 10% testing.\n",
    "    train_size = int(dataset_len * 0.7)\n",
    "    eval_size = int(dataset_len * 0.2)\n",
    "    train, val, test = dataset[:train_size], dataset[train_size:train_size + eval_size], dataset[train_size + eval_size:]\n",
    "    return train, val, test\n",
    "\n",
    "def write_csv(filename, enc_data, dec_data):\n",
    "    df = pd.DataFrame({'Text': enc_data, 'Summary': dec_data})\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "def main():\n",
    "    summary_datapath = '/home/Bengali-News-Summarization-Dataset/summary.txt'\n",
    "    article_datapath = '/home/Bengali-News-Summarization-Dataset/article.txt'\n",
    "    \n",
    "    dec_train, dec_val, dec_test = split_dataset(summary_datapath)\n",
    "    enc_train, enc_val, enc_test = split_dataset(article_datapath)\n",
    "    \n",
    "    # Create the directory if it doesn't exist\n",
    "    directory = './datasetFull'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    write_csv(os.path.join(directory, 'train.csv'), enc_train, dec_train)\n",
    "    write_csv(os.path.join(directory, 'val.csv'), enc_val, dec_val)\n",
    "    write_csv(os.path.join(directory, 'test.csv'), enc_test, dec_test)\n",
    "    \n",
    "    print(\"Finished splitting and saving dataset!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-output": true,
    "id": "g3agEMJEnKsl",
    "outputId": "56ab843a-e9c8-4158-8c04-18d77aec44fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qqq torch==2.0.1 loralib==0.1.1 einops==0.6.1 pandas\n",
    "!pip install -q -U bitsandbytes transformers peft accelerate datasets scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc68127f45104990be58112694c43a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install -q --upgrade huggingface_hub\n",
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dv3aJo8Anhyw",
    "outputId": "66f7b274-28a9-45b4-c0e6-d25194424594"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from pprint import pprint\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import load_dataset, Dataset\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "from peft import LoraConfig, PeftConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mllA2Ka_ol13"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40857d2f5e464648a42478b0a0817c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = \"google/gemma-7b-it\"\n",
    "new_model = \"gemma7b-it_banglaNewsSum\"\n",
    "\n",
    "MODEL_NAME = model\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=bnb_config\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "na8DUq4IoqpB"
   },
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_num_layers(model):\n",
    "    numbers = set()\n",
    "    for name, _ in model.named_parameters():\n",
    "        for number in re.findall(r'\\d+', name):\n",
    "            numbers.add(int(number))\n",
    "    return max(numbers)\n",
    "\n",
    "def get_last_layer_linears(model):\n",
    "    names = []\n",
    "    \n",
    "    num_layers = get_num_layers(model)\n",
    "    for name, module in model.named_modules():\n",
    "        if str(num_layers) in name and not \"encoder\" in name:\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                names.append(name)\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "C4Qk3fGLoraw"
   },
   "outputs": [],
   "source": [
    "config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=get_last_layer_linears(model),\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['base_model.model.model.layers.27.self_attn.q_proj.base_layer',\n",
       " 'base_model.model.model.layers.27.self_attn.q_proj.lora_A.default',\n",
       " 'base_model.model.model.layers.27.self_attn.q_proj.lora_B.default',\n",
       " 'base_model.model.model.layers.27.self_attn.k_proj.base_layer',\n",
       " 'base_model.model.model.layers.27.self_attn.k_proj.lora_A.default',\n",
       " 'base_model.model.model.layers.27.self_attn.k_proj.lora_B.default',\n",
       " 'base_model.model.model.layers.27.self_attn.v_proj.base_layer',\n",
       " 'base_model.model.model.layers.27.self_attn.v_proj.lora_A.default',\n",
       " 'base_model.model.model.layers.27.self_attn.v_proj.lora_B.default',\n",
       " 'base_model.model.model.layers.27.self_attn.o_proj.base_layer',\n",
       " 'base_model.model.model.layers.27.self_attn.o_proj.lora_A.default',\n",
       " 'base_model.model.model.layers.27.self_attn.o_proj.lora_B.default',\n",
       " 'base_model.model.model.layers.27.mlp.gate_proj.base_layer',\n",
       " 'base_model.model.model.layers.27.mlp.gate_proj.lora_A.default',\n",
       " 'base_model.model.model.layers.27.mlp.gate_proj.lora_B.default',\n",
       " 'base_model.model.model.layers.27.mlp.up_proj.base_layer',\n",
       " 'base_model.model.model.layers.27.mlp.up_proj.lora_A.default',\n",
       " 'base_model.model.model.layers.27.mlp.up_proj.lora_B.default',\n",
       " 'base_model.model.model.layers.27.mlp.down_proj.base_layer',\n",
       " 'base_model.model.model.layers.27.mlp.down_proj.lora_A.default',\n",
       " 'base_model.model.model.layers.27.mlp.down_proj.lora_B.default']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_last_layer_linears(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/home/datasetFull/train.csv\", encoding = 'utf-8')\n",
    "train_df.columns = [str(q) for q in train_df.columns]\n",
    "\n",
    "val_df = pd.read_csv(\"/home/datasetFull/val.csv\", encoding = 'utf-8')\n",
    "val_df.columns = [str(q) for q in val_df.columns]\n",
    "\n",
    "test_df = pd.read_csv(\"/home/datasetFull/test.csv\", encoding = 'utf-8')\n",
    "test_df.columns = [str(q) for q in test_df.columns]\n",
    "\n",
    "train_data = Dataset.from_pandas(train_df)\n",
    "val_data = Dataset.from_pandas(val_df)\n",
    "test_data = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ঢাকার আশুলিয়ার এক বাড়িতে আগুন লেগে পাঁচটি ঘর পুড়ে গেছে।',\n",
       "       'পায়ুপথে লুকিয়ে সোনার বিস্কুট পাচারের সময় চট্টগ্রামের শাহ আমানত বিমানবন্দর থেকে এক যাত্রীকে গ্রেপ্তার করেছেন শুল্ক গোয়েন্দারা।',\n",
       "       'সিরাজগঞ্জের চৌহালী উপজেলার এনায়েতপুরে যমুনা নদীর স্পার বাঁধ এলাকা থেকে এক শিশু ও দুই নারীর বস্তাবন্দি লাশ উদ্ধার করেছে পুলিশ।',\n",
       "       'পুরান ঢাকার নাজিমউদ্দিন রোডের পরিত্যাক্ত ঢাকা কেন্দ্রীয় কারাগারে প্রধানমন্ত্রী প্রতিশ্রুত প্রকল্প দ্রুত বাস্তবায়নের দাবি জানিয়েছে ঢাকা মহানগরী সমিতি। সেখানে যেন অন্য কোনো স্থাপনা তৈরি না করা হয়, সেই অনুরোধও জানিয়েছেন সংগঠনের নেতারা।',\n",
       "       'নড়াইলে ইসলামী ছাত্রশিবিরের এক নেতাকে হাতবোমা, ও উগ্র মতবাদের বইসহ গ্রেপ্তার করেছে পুলিশ।'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"Text\"].values[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['আশুলিয়ায় পুড়ল ৫ ঘর', 'পায়ুপথে লুকিয়ে ১২ সোনার বিস্কুট',\n",
       "       'সিরাজগঞ্জে এক শিশু ও দুই নারীর বস্তাবন্দি লাশ',\n",
       "       'ঢাকা কারাগারে প্রতিশ্রুত প্রকল্প বাস্তবায়নের দাবি ঢাকা সমিতির',\n",
       "       'নড়াইলে হাতবোমাসহ শিবির নেতা গ্রেপ্তার'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"Summary\"].values[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "_Pb9RA5NovNS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<start_of_turn>\\nProvide a concise Bengali summary of the following news article, focusing on the most important information. \\n\\nNote:\\nUse only Bengali for the summary.\\nStay objective and factual in your summary.\\n\\n####\\n\\nArticle: ঢাকার আশুলিয়ার এক বাড়িতে আগুন লেগে পাঁচটি ঘর পুড়ে গেছে।\\n\\n####\\n<end_of_turn>\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "<start_of_turn>\n",
    "Provide a concise Bengali summary of the following news article, focusing on the most important information. \n",
    "\n",
    "Note:\n",
    "Use only Bengali for the summary.\n",
    "Stay objective and factual in your summary.\n",
    "\n",
    "####\n",
    "\n",
    "Article: {train_df[\"Text\"].values[0]}\n",
    "\n",
    "####\n",
    "<end_of_turn>\n",
    "\"\"\"\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YiqCdCD2oyPH"
   },
   "outputs": [],
   "source": [
    "generation_config = model.generation_config\n",
    "generation_config.max_new_tokens = 50\n",
    "generation_config.temperature = 0.7\n",
    "generation_config.top_p = 0.7\n",
    "generation_config.num_return_sequences = 1\n",
    "generation_config.pad_token_id = tokenizer.eos_token_id\n",
    "generation_config.eos_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "o2ELFG0no1xR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Provide a concise Bengali summary of the following news article, focusing on the most important information. \n",
      "\n",
      "Note:\n",
      "Use only Bengali for the summary.\n",
      "Stay objective and factual in your summary.\n",
      "\n",
      "####\n",
      "\n",
      "Article: ঢাকার আশুলিয়ার এক বাড়িতে আগুন লেগে পাঁচটি ঘর পুড়ে গেছে।\n",
      "\n",
      "####\n",
      "\n",
      "**Summary:**\n",
      "\n",
      "ঢাকার আশুলিয়ার এক বাড়িতে আগুন লেগে পাঁচটি ঘর পুড়ে গেছে। আগুনটি পুড়ে প্রথমে\n",
      "Actual Summary: আশুলিয়ায় পুড়ল ৫ ঘর\n",
      "CPU times: user 4.82 s, sys: 84.1 ms, total: 4.9 s\n",
      "Wall time: 4.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "device = \"cuda\"\n",
    "\n",
    "encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        input_ids = encoding.input_ids,\n",
    "        attention_mask = encoding.attention_mask,\n",
    "        generation_config = generation_config\n",
    "    )\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "print('Actual Summary:', train_df[\"Summary\"].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "lm60o2_No7Jz"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf17af1968e54bf0aeaa2d4edafa14ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13367 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98a94ed2f0d45468e0db698cdd02da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3819 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c214f6764d30492f9060ab1a738b3867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1911 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_prompt(data_point):\n",
    "    return f\"\"\"\n",
    "<start_of_turn>\n",
    "Provide a concise Bengali summary of the following news article, focusing on the most important information. \n",
    "\n",
    "Note:\n",
    "Use only Bengali for the summary.\n",
    "Stay objective and factual in your summary.\n",
    "\n",
    "####\n",
    "\n",
    "Article: {data_point[\"Text\"]}\n",
    "\n",
    "####\n",
    "<end_of_turn>\n",
    "\n",
    "<start_of_turn>\n",
    "####\n",
    "\n",
    "Summary: {data_point[\"Summary\"]} \n",
    "\n",
    "####\n",
    "<end_of_turn>\n",
    "\"\"\".strip()\n",
    "\n",
    "def generate_and_tokenize_prompt(data_point):\n",
    "    full_prompt = generate_prompt(data_point)\n",
    "    tokenized_full_prompt = tokenizer(full_prompt, padding=True, truncation=True)\n",
    "    return tokenized_full_prompt\n",
    "\n",
    "train_data = train_data.shuffle().map(generate_and_tokenize_prompt)\n",
    "val_data = val_data.shuffle().map(generate_and_tokenize_prompt)\n",
    "test_data = test_data.shuffle().map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PGneIe1xpUJV",
    "outputId": "8cdac9ac-d6bf-4d8f-b954-febf7f140591",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 4:40:02, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>10.505700</td>\n",
       "      <td>10.128615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>9.378400</td>\n",
       "      <td>8.253196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>6.626000</td>\n",
       "      <td>4.804269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.205000</td>\n",
       "      <td>2.168969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.931900</td>\n",
       "      <td>1.643880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.557900</td>\n",
       "      <td>1.494015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.458200</td>\n",
       "      <td>1.430442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.401700</td>\n",
       "      <td>1.370473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.355000</td>\n",
       "      <td>1.335944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.315100</td>\n",
       "      <td>1.310295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.296700</td>\n",
       "      <td>1.295422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.282300</td>\n",
       "      <td>1.288981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.288100</td>\n",
       "      <td>1.287657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=260, training_loss=3.2770693999070386, metrics={'train_runtime': 16852.8414, 'train_samples_per_second': 3.966, 'train_steps_per_second': 0.015, 'total_flos': 7.048804415292273e+17, 'train_loss': 3.2770693999070386, 'epoch': 4.98})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=f\"./{new_model}\",\n",
    "    save_strategy=\"steps\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    gradient_accumulation_steps=16,\n",
    "    num_train_epochs=5,\n",
    "    logging_steps=20,\n",
    "    eval_steps=20,\n",
    "    save_steps=20,\n",
    "    warmup_steps=100,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.01,\n",
    "    report_to=\"none\",\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    args=training_args,\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=f\"./{new_model}\",\n",
    "    save_strategy=\"steps\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    gradient_accumulation_steps=16,\n",
    "    num_train_epochs=5,\n",
    "    logging_steps=20,\n",
    "    eval_steps=20,\n",
    "    save_steps=20,\n",
    "    warmup_steps=100,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.01,\n",
    "    report_to=\"none\",\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    args=training_args,\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc2f28736b1f4f54bb429631e1d84863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:834: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2418d9e0e64c4c03995c987204bfbc07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/3.57M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/samanjoy2/gemma7b-it_banglaNewsSum/commit/66dd1222146dce9e0989eb90c969602651f092bd', commit_message='Upload model', commit_description='', oid='66dd1222146dce9e0989eb90c969602651f092bd', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PEFT_MODEL = f\"samanjoy2/{new_model}\"\n",
    "\n",
    "model.push_to_hub(\n",
    "    PEFT_MODEL, use_auth_token=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Vmce-aSesAHV",
    "outputId": "4bf93e78-2a0b-404c-8b05-3748db1bdc52"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89eaa257c0be4fd7abcc6e11f0c64495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model.save_pretrained(\"trained-model\")\n",
    "\n",
    "PEFT_MODEL = new_model\n",
    "\n",
    "config = PeftConfig.from_pretrained(PEFT_MODEL)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    return_dict=True,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = PeftModel.from_pretrained(model, PEFT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "vgIHyPUasD0b"
   },
   "outputs": [],
   "source": [
    "generation_config = model.generation_config\n",
    "generation_config.max_new_tokens = 50\n",
    "generation_config.temperature = 0.7\n",
    "generation_config.top_p = 0.7\n",
    "generation_config.num_return_sequences = 1\n",
    "generation_config.pad_token_id = tokenizer.eos_token_id\n",
    "generation_config.eos_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "I--juWjcCGpS"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>নাশকতা ও রাষ্ট্রদ্রোহের দশ মামলায় আদালতে হাজির...</td>\n",
       "      <td>১০ মামলায় খালেদার জামিন</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ভুল চুলের ছাঁট, রং বা স্টাইলের কারণে বয়স বেশি ...</td>\n",
       "      <td>কেশশৈলীর ৫ ভুল: দেখতে লাগবে বুড়োটে</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ঢাকা সিটি করপোরেশন নির্বাচনে নাগরিক সমস্যার সম...</td>\n",
       "      <td>সমস্যা সমাধানে প্রাধান্য উত্তরের ভোটারদের</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>লন্ডন থেকে বাংলাদেশ দলকে বিদায় জানিয়েছে বৃষ্টি...</td>\n",
       "      <td>নিউ জিল্যান্ড বলেই আশায় সাকিব</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>নিজেদের পণ্য ও সেবার সাইবার নিরাপত্তা দূর্বলতা...</td>\n",
       "      <td>ত্রুটি খুঁজতে পারিশ্রমিক দেবে গুগল</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>কাজাখস্তানের রাজধানী আসতানায় অনুষ্ঠিত সিরিয়া ব...</td>\n",
       "      <td>সিরিয়ায় নিরাপদ অঞ্চল প্রতিষ্ঠার চুক্তি কার্যকর...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>যুক্তরাজ্যের প্রভাবশালী দ্য গার্ডিয়ান পত্রিকার...</td>\n",
       "      <td>গার্ডিয়ানএ প্রথম নারী সম্পাদক</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>গত বছরের শুরুতে ওয়ানডেতে অভিষিক্ত হওয়া আরাফাত ...</td>\n",
       "      <td>বিশ্বকাপ দলে ডাক পেয়ে রোমাঞ্চিত সানি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>সেক্টর কমান্ডার্স ফোরাম, যুক্তরাষ্ট্র শাখার উদ...</td>\n",
       "      <td>যুক্তরাষ্ট্রে সেক্টর কমান্ডার্স ফোরামের মতবিনিময়</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>জাহাঙ্গীরনগর বিশ্ববিদ্যালয় থেকে এক শিক্ষার্থীক...</td>\n",
       "      <td>জাবি শিক্ষার্থীকে নিয়ে গেছে আইনশৃঙ্খলা বাহিনী</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1911 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  \\\n",
       "0     নাশকতা ও রাষ্ট্রদ্রোহের দশ মামলায় আদালতে হাজির...   \n",
       "1     ভুল চুলের ছাঁট, রং বা স্টাইলের কারণে বয়স বেশি ...   \n",
       "2     ঢাকা সিটি করপোরেশন নির্বাচনে নাগরিক সমস্যার সম...   \n",
       "3     লন্ডন থেকে বাংলাদেশ দলকে বিদায় জানিয়েছে বৃষ্টি...   \n",
       "4     নিজেদের পণ্য ও সেবার সাইবার নিরাপত্তা দূর্বলতা...   \n",
       "...                                                 ...   \n",
       "1906  কাজাখস্তানের রাজধানী আসতানায় অনুষ্ঠিত সিরিয়া ব...   \n",
       "1907  যুক্তরাজ্যের প্রভাবশালী দ্য গার্ডিয়ান পত্রিকার...   \n",
       "1908  গত বছরের শুরুতে ওয়ানডেতে অভিষিক্ত হওয়া আরাফাত ...   \n",
       "1909  সেক্টর কমান্ডার্স ফোরাম, যুক্তরাষ্ট্র শাখার উদ...   \n",
       "1910  জাহাঙ্গীরনগর বিশ্ববিদ্যালয় থেকে এক শিক্ষার্থীক...   \n",
       "\n",
       "                                                Summary  \n",
       "0                               ১০ মামলায় খালেদার জামিন  \n",
       "1                    কেশশৈলীর ৫ ভুল: দেখতে লাগবে বুড়োটে  \n",
       "2             সমস্যা সমাধানে প্রাধান্য উত্তরের ভোটারদের  \n",
       "3                         নিউ জিল্যান্ড বলেই আশায় সাকিব  \n",
       "4                    ত্রুটি খুঁজতে পারিশ্রমিক দেবে গুগল  \n",
       "...                                                 ...  \n",
       "1906  সিরিয়ায় নিরাপদ অঞ্চল প্রতিষ্ঠার চুক্তি কার্যকর...  \n",
       "1907                      গার্ডিয়ানএ প্রথম নারী সম্পাদক  \n",
       "1908               বিশ্বকাপ দলে ডাক পেয়ে রোমাঞ্চিত সানি  \n",
       "1909   যুক্তরাষ্ট্রে সেক্টর কমান্ডার্স ফোরামের মতবিনিময়  \n",
       "1910      জাবি শিক্ষার্থীকে নিয়ে গেছে আইনশৃঙ্খলা বাহিনী  \n",
       "\n",
       "[1911 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'নাশকতা ও রাষ্ট্রদ্রোহের দশ মামলায় আদালতে হাজির হয়ে জামিন পেয়েছেন বিএনপি চেয়ারপারসন খালেদা জিয়া।'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"Text\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "63Zxai-isGhJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models Summary অর্থমন্ত্রী আবুল মাল আবদুল মুহিত\n",
      "Actual Summary: দেশে ২০২৪ সালের পর কেউ গরীব থাকবে না: অর্থমন্ত্রী\n",
      "CPU times: user 4.78 s, sys: 7.72 ms, total: 4.78 s\n",
      "Wall time: 4.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prompt = f\"\"\"\n",
    "<start_of_turn>\n",
    "Provide a concise Bengali summary of the following news article, focusing on the most important information. \n",
    "\n",
    "Note:\n",
    "Use only Bengali for the summary.\n",
    "Stay objective and factual in your summary.\n",
    "\n",
    "####\n",
    "\n",
    "Article: {train_df[\"Text\"].values[7]}\n",
    "\n",
    "####\n",
    "<end_of_turn>\n",
    "\"\"\"\n",
    "\n",
    "device = \"cuda\"\n",
    "encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "with torch.inference_mode():\n",
    "  outputs = model.generate(\n",
    "      input_ids = encoding.input_ids,\n",
    "      attention_mask = encoding.attention_mask,\n",
    "      generation_config = generation_config\n",
    "  )\n",
    "\n",
    "# generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True).split('[/INST]')[1].split('\\n')\n",
    "# print(generated_text)\n",
    "print('Models Summary', tokenizer.decode(outputs[0], skip_special_tokens=True).split('Summary:')[1].split('\\n')[0].strip())\n",
    "print('Actual Summary:', train_df[\"Summary\"].values[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 900472,
     "sourceId": 1527319,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 8318,
     "sourceId": 11382,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 3097,
     "sourceId": 4302,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
